---
title: "Venice"
description: "Learn how to configure and use Venice AI models with Cline. Venice provides privacy-first AI with no data retention and OpenAI-compatible API."
---

Venice AI is a privacy-first AI platform that provides access to powerful language models with no data retention, permissionless access, and OpenAI-compatible API endpoints.

**Website:** [https://venice.ai/](https://venice.ai/)

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [Venice AI website](https://venice.ai/) and create an account or sign in.
2. **Navigate to API Settings:** Go to the [API Settings page](https://venice.ai/settings/api) or click "API" in the left toolbar.
3. **Generate New API Key:** Scroll down and click "Generate New API Key".
4. **Configure Key Settings:**
   - Give your key a descriptive name (e.g., "Cline")
   - Choose "Inference Only" for regular usage
   - Optional expiration date and usage limits
5. **Copy the Key:** Click "Generate" and **immediately copy the API key**. This key is only shown once and cannot be retrieved later.

### Supported Models

Venice offers four distinct models with different capabilities:

#### **qwen3-235b** (Large Model)
- **Context Window:** 131,072 tokens
- **Max Output:** 32,768 tokens  
- **Special Features:** Advanced reasoning, function calling, web search, structured responses
- **Best For:** Complex reasoning tasks, coding projects, and detailed analysis
- **Pricing:** $0.90/1M input, $4.50/1M output tokens

#### **mistral-31-24b** (Vision Model)
- **Context Window:** 131,072 tokens
- **Max Output:** 32,768 tokens
- **Special Features:** Image understanding, function calling, web search, vision processing
- **Best For:** Multimodal tasks requiring both text and image analysis
- **Pricing:** $0.50/1M input, $2.00/1M output tokens

#### **qwen3-4b** (Small Model)
- **Context Window:** 40,960 tokens
- **Max Output:** 8,192 tokens
- **Special Features:** Reasoning capabilities, function calling, web search
- **Best For:** Fast inference, cost-effective tasks, general programming
- **Pricing:** $0.05/1M input, $0.15/1M output tokens

#### **venice-uncensored** (Default)
- **Context Window:** 32,768 tokens
- **Max Output:** 8,192 tokens
- **Special Features:** No content filtering, function calling, web search, structured responses
- **Best For:** Creative tasks without content restrictions
- **Pricing:** $0.20/1M input, $0.90/1M output tokens

### Configuration in Cline

1. **Open Cline Settings:** Click the settings icon (⚙️) in the Cline panel.
2. **Select Provider:** Choose "Venice" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your Venice API key into the "Venice API Key" field.
4. **Select Model:** Choose your desired model from the "Model" dropdown.
5. **Configure Venice Parameters:** Customize the Venice-specific options below.

#### Venice Parameters

Venice provides several configurable parameters to customize model behavior:

##### **Web Search**
Controls when the model should perform web searches:
- **Auto** (default): Let the model decide when to search
- **On**: Always enable web search capabilities
- **Off**: Disable web search entirely

##### **Include Search Results in Stream**
When web search is enabled, this option controls whether search results are included in the response stream. Enable this to see what sources the model found during web searches.

##### **Include Venice System Prompt**
Venice provides default system prompts designed for uncensored and natural responses. You can choose to:
- **Enabled**: Your prompts are appended to Venice's default system prompts
- **Disabled**: Use only your custom system prompts

##### **Reasoning Controls** (qwen3-4b and qwen3-235b only)
For reasoning-capable models, additional controls are available:

- **Strip Thinking from Response**: Remove the `<think>` tags and reasoning process from the final response, showing only conclusions
- **Disable Thinking Mode**: Turn off the step-by-step reasoning process entirely for faster responses

### Venice Parameters in Practice

When you select Venice as your provider, you'll see additional configuration options in the Cline settings panel:

1. **Web Search dropdown**: Choose between Auto/On/Off
2. **Include search results in stream**: Checkbox (only visible when web search is not "Off")
3. **Include Venice system prompt**: Checkbox for system prompt behavior
4. **Reasoning controls**: Additional checkboxes for thinking controls (only for qwen3-4b and qwen3-235b models)

These parameters are automatically saved with your workspace configuration and will be remembered across Cline sessions. The reasoning controls will only appear when you select a reasoning-capable model.

### Privacy-First Architecture

Venice's core philosophy centers on user privacy and data protection:

#### No Data Retention
Venice does not store, log, or retain any of your conversations or API requests. Your data is processed in real-time and immediately discarded.

#### Permissionless Access
No approval processes, waiting periods, or content review. Start using Venice immediately after account creation.

#### OpenAI Compatibility
Venice provides full OpenAI API compatibility, making it easy to integrate with existing workflows and tools that use OpenAI's format.

### Special Features

Venice models come with several built-in capabilities that enhance their functionality:

#### **Function Calling / Tools**
All Venice models support function calling, allowing them to use external tools and APIs. This enables:
- Web searches and real-time information retrieval
- API integrations and database queries  
- Custom function execution

#### **Web Search Integration**
All Venice models can perform real-time web searches with:
- Automatic search query generation
- Source citations and references
- Up-to-date information retrieval
- Configurable search behavior (`auto`, `on`, `off`)

#### **Vision Processing** (mistral-31-24b only)
The Mistral model provides advanced image understanding:
- Image analysis and description
- Visual question answering
- Chart and diagram interpretation
- Combined vision + web search capabilities

#### **Reasoning Mode** (qwen3-235b, qwen3-4b)
Select models offer enhanced reasoning with:
- Step-by-step problem solving
- Visible thinking process in `<think>` tags
- Configurable reasoning display options
- Advanced mathematical and logical reasoning

#### **Structured Responses**
Most Venice models support JSON schema-based structured outputs:
- Guaranteed response format compliance
- Reduced hallucination in structured data
- OpenAI-compatible `response_format` parameter
- Perfect for data extraction and API responses

#### **No Content Filtering** (venice-uncensored)
The uncensored model provides:
- Minimal content restrictions
- Creative freedom for artistic work
- Research and educational applications
- Full capability access without filtering

### Tips and Notes

- **Model Selection:** Choose models based on your specific needs:
  - Use `qwen3-4b` for cost-effective general tasks with reasoning capabilities
  - Use `mistral-31-24b` when you need vision capabilities
  - Use `qwen3-235b` for complex reasoning tasks requiring maximum capability
  - Use `venice-uncensored` for unrestricted content generation
- **Reasoning Models:** Only `qwen3-4b` and `qwen3-235b` support advanced reasoning with thinking controls
- **Web Search:** All models support web search, but you can control when and how it's used
- **Privacy Advantage:** Venice's no-data-retention policy makes it ideal for sensitive or proprietary work
- **Pricing:** Venice uses transparent pay-per-use pricing per 1M tokens. Check the [Venice Models page](https://docs.venice.ai/overview/models) for current rates
- **API Compatibility:** Venice is fully compatible with OpenAI SDKs and existing code
- **Parameter Persistence:** All Venice parameter settings are saved per workspace and persist across Cline sessions